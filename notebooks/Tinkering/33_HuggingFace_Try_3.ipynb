{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5580d2e5-b30d-4d81-95d9-c731a4f9d6b3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HF Fine Tune 3 \n",
    "From article https://www.hackster.io/shahizat/fine-tuning-llms-using-nvidia-jetson-agx-orin-b17c4d#overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466fe3d9-0973-45a5-997f-71c36c38fa69",
   "metadata": {},
   "source": [
    "## Part 1 - Load the Training Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5ad31f-e102-438a-85e2-6139a96fa470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install Libraries \n",
    "from datasets import load_dataset \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f299fc8d-00d2-4201-a084-596e6986ef0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# load training dataset \n",
    "dataset = load_dataset(\"timdettmers/openassistant-guanaco\")\n",
    "df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fdca787-ddef-459a-8ff0-f7177a4e563c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>### Human: Can you write a short introduction ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>### Human: ¿CUales son las etapas del desarrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>### Human: Can you explain contrastive learnin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>### Human: I want to start doing astrophotogra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>### Human: Método del Perceptrón biclásico: de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  ### Human: Can you write a short introduction ...\n",
       "1  ### Human: ¿CUales son las etapas del desarrol...\n",
       "2  ### Human: Can you explain contrastive learnin...\n",
       "3  ### Human: I want to start doing astrophotogra...\n",
       "4  ### Human: Método del Perceptrón biclásico: de..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95438b07-1a69-4d62-81cd-fb33ea8ca479",
   "metadata": {},
   "source": [
    "## Part 2 - Train the model in batches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cbb6113-d9c8-49a4-ba32-c896fabd06fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load your libraries \n",
    "import os\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, prepare_model_for_kbit_training\n",
    "from huggingface_hub import login\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    AutoTokenizer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from trl import SFTTrainer\n",
    "import wandb\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e99b574c-d603-4ccd-b256-ae9116e6bdeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: read).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "# Define login sequence \n",
    "login(\n",
    "  token=\"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\", # ADD YOUR TOKEN HERE\n",
    "  add_to_git_credential=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55ade5bf-d285-4851-b4f4-4c804522351d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set your output directory \n",
    "output_dir=\"./fine-tuned_mistral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b507dca-b680-4a1b-95c1-1f47bc58fda0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f9c4278e714250b5b52ed1e5cf4001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/996 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5de26708d21947bcb37adc35a0b5c14e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a0d28231704b04b03c85468f5615a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e1d6e5cbfa4b329bf3829f0caa1367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the model \n",
    "model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "# Define the Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.pad_token_id =  tokenizer.unk_token_id\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "028b1f63-5ba4-49b6-821f-3897bb33887f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure Torch parameters \n",
    "compute_dtype = getattr(torch, \"bfloat16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cca6ea3f-854f-471d-af30-d4b49fa47caa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: bitsandbytes in /usr/local/lib/python3.8/dist-packages (0.42.0)\n",
      "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.8/dist-packages (from bitsandbytes) (1.10.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.8/dist-packages (from scipy->bitsandbytes) (1.21.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de9983e-a458-437d-a52c-d3fbd1f60c88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_785/925666306.py\", line 2, in <module>\n",
      "    model = AutoModelForCausalLM.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/models/auto/auto_factory.py\", line 564, in from_pretrained\n",
      "    return model_class.from_pretrained(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/modeling_utils.py\", line 3354, in from_pretrained\n",
      "    hf_quantizer.validate_environment(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\", line 66, in validate_environment\n",
      "    raise ImportError(\n",
      "ImportError: Using `bitsandbytes` 4-bit quantization requires the latest version of bitsandbytes: `pip install -U bitsandbytes`\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 799, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/IPython/core/ultratb.py\", line 845, in get_records\n",
      "    style = stack_data.style_with_executing_node(style, self._tb_highlight)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/stack_data/core.py\", line 455, in style_with_executing_node\n",
      "    class NewStyle(style):\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 91, in __new__\n",
      "    ndef[4] = colorformat(styledef[3:])\n",
      "  File \"/usr/lib/python3/dist-packages/pygments/style.py\", line 58, in colorformat\n",
      "    assert False, \"wrong color format %r\" % text\n",
      "AssertionError: wrong color format 'ansiyellow'\n"
     ]
    }
   ],
   "source": [
    "# Define your Model \n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "          model_name, quantization_config=bnb_config, device_map={\"\": 0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf099c2-aaf0-499c-bf22-462d3df9a6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
