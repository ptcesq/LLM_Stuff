{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tune Distilgpt2 \n",
    "This notebook takes DistilGPT2 and fine tunes it with a short blurb.  That result is compared with the pre-trained model. \n",
    "Next step in 008A is to substitute the short blurb with a Q&A document.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ItYpaZD9EH7J"
   },
   "outputs": [],
   "source": [
    "# Load Libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "import os\n",
    "import docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Ly_QfYPDHlie"
   },
   "outputs": [],
   "source": [
    "# Functions to read different file types\n",
    "def read_pdf(file_path):\n",
    "    with open(file_path, \"rb\") as file:\n",
    "        pdf_reader = PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            text += pdf_reader.pages[page_num].extract_text()\n",
    "    return text\n",
    "\n",
    "def read_word(file_path):\n",
    "    doc = docx.Document(file_path)\n",
    "    text = \"\"\n",
    "    for paragraph in doc.paragraphs:\n",
    "        text += paragraph.text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "def read_txt(file_path):\n",
    "    with open(file_path, \"r\") as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def read_documents_from_directory(directory):\n",
    "    combined_text = \"\"\n",
    "    for filename in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if filename.endswith(\".pdf\"):\n",
    "            combined_text += read_pdf(file_path)\n",
    "        elif filename.endswith(\".docx\"):\n",
    "            combined_text += read_word(file_path)\n",
    "        elif filename.endswith(\".txt\"):\n",
    "            combined_text += read_txt(file_path)\n",
    "    return combined_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oobynnecHx87"
   },
   "outputs": [],
   "source": [
    "# Read documents from the directory\n",
    "train_directory = \"C:\\\\Users\\\\patri\\\\projects\\\\GenAI\\\\data\\\\privacy\\\\train_directory\"\n",
    "text_data = read_documents_from_directory(train_directory)\n",
    "text_data = re.sub(r'\\n+', '\\n', text_data).strip()  # Remove excess newline characters\n",
    "text_data = re.sub(r'[^A-Za-z0-9 ]+', '', text_data) # Remove any non-alphameric characters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8RCPr_L0uJdo"
   },
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\patri\\\\projects\\\\GenAI\\\\data\\\\privacy\\\\model_cache\\\\train.txt\", \"w\") as f:\n",
    "    f.write(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9MFaNgaDEVKP"
   },
   "outputs": [],
   "source": [
    "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Wk_14dI9EVdD"
   },
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, block_size = 128):\n",
    "    dataset = TextDataset(\n",
    "        tokenizer = tokenizer,\n",
    "        file_path = file_path,\n",
    "        block_size = block_size,\n",
    "    )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QJcoT-aNFcKp"
   },
   "outputs": [],
   "source": [
    "def load_data_collator(tokenizer, mlm = False):\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=tokenizer, \n",
    "        mlm=mlm,\n",
    "    )\n",
    "    return data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ub3THjJ_FdSw"
   },
   "outputs": [],
   "source": [
    "def train(train_file_path,model_name,\n",
    "          output_dir,\n",
    "          overwrite_output_dir,\n",
    "          per_device_train_batch_size,\n",
    "          num_train_epochs,\n",
    "          save_steps):\n",
    "  tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "  train_dataset = load_dataset(train_file_path, tokenizer)\n",
    "  data_collator = load_data_collator(tokenizer)\n",
    "\n",
    "  tokenizer.save_pretrained(output_dir)\n",
    "      \n",
    "  model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "  model.save_pretrained(output_dir)\n",
    "\n",
    "  training_args = TrainingArguments(\n",
    "          output_dir=output_dir,\n",
    "          overwrite_output_dir=overwrite_output_dir,\n",
    "          per_device_train_batch_size=per_device_train_batch_size,\n",
    "          num_train_epochs=num_train_epochs,\n",
    "      )\n",
    "\n",
    "  trainer = Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          data_collator=data_collator,\n",
    "          train_dataset=train_dataset,\n",
    "  )\n",
    "      \n",
    "  trainer.train()\n",
    "  trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "9mXiWKHbFr2f"
   },
   "outputs": [],
   "source": [
    "# Set the hyper-parameters \n",
    "train_file_path = \"C:\\\\Users\\\\patri\\\\projects\\\\GenAI\\\\data\\\\privacy\\\\model_cache\\\\train.txt\"\n",
    "model_name = 'gpt2'\n",
    "output_dir = \"C:\\\\Users\\\\patri\\\\projects\\\\GenAI\\\\data\\\\privacy\\\\refinded_models\"\n",
    "overwrite_output_dir = False\n",
    "per_device_train_batch_size = 8\n",
    "num_train_epochs = 50.0\n",
    "save_steps = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "WMdaTo7KF9uo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patri\\anaconda3\\Lib\\site-packages\\transformers\\data\\datasets\\language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 1:24:40, Epoch 50/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "train(\n",
    "    train_file_path=train_file_path,\n",
    "    model_name=model_name,\n",
    "    output_dir=output_dir,\n",
    "    overwrite_output_dir=overwrite_output_dir,\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    save_steps=save_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xwGS1IMlGBMB"
   },
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lelq_sN4Gy5M"
   },
   "outputs": [],
   "source": [
    "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel, GPT2TokenizerFast, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "wOvrNQRAG2IP"
   },
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    model = GPT2LMHeadModel.from_pretrained(model_path)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_tokenizer(tokenizer_path):\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained(tokenizer_path)\n",
    "    return tokenizer\n",
    "\n",
    "def generate_text(model_path, sequence, max_length):\n",
    "    \n",
    "    model = load_model(model_path)\n",
    "    tokenizer = load_tokenizer(model_path)\n",
    "    ids = tokenizer.encode(f'{sequence}', return_tensors='pt')\n",
    "    final_outputs = model.generate(\n",
    "        ids,\n",
    "        do_sample=True,\n",
    "        max_length=max_length,\n",
    "        pad_token_id=model.config.eos_token_id,\n",
    "        top_k=50,\n",
    "        top_p=0.95,\n",
    "    )\n",
    "    print(tokenizer.decode(final_outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvNx7gjeRieD"
   },
   "source": [
    "This model got trained on the entire text and took much longer to train, but gives a decent answer.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5mTDTrpnG5Ut",
    "outputId": "e37387f1-beb6-4fa6-d5fd-ec2dfd775978",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Q] What is the Privacy Act of 1974?  The Privacy Act of 1974 was a bill Congress enacted to provide for the management of personal information  It was the first comprehensive privacy law in the country to allow the government to regulate the use of personal information by federal agencies  It was later modified by the Computer Matching and Privacy Protection Act of 1988 gifmitting the Privacy Act jurisdiction over computermatching and matching activities by agencies  These included the Department of Health and Human Services  Office of Privacy and Civil Liberties OVERVIEW OF THE PRIVACY ACT Regulation EU 2016679 of the European Parliament and of the Council of 27 October 2016 on the Protection of Natural Persons with Regard to the Processing of Personal Data and on the Free Movement of Such Data known as the General Data Protection Regulation GDPR The GrammLeachBliley Act 14 USC  6801 The Health Insurance Portability and Accountability Act of 1974 Pub L No 100503 102 Stat 2507 extending the Privacy Acts FIPPsbased rights of privacy to commerce by curtailing the collection and use of personal data by agencies operating without a warrant and by extending the Privacy Acts Privacy Ratifications to Contracts Enacted in the wake of the Watergate and COINTELPRO scandals Congress enacted the Cybersecurity Act of 1996 Pub L\n"
     ]
    }
   ],
   "source": [
    "model1_path = \"C:\\\\Users\\\\patri\\\\projects\\\\GenAI\\\\data\\\\privacy\\\\refinded_models\"\n",
    "sequence1 = \"[Q] What is the Privacy Act of 1974?\"\n",
    "max_len = 256\n",
    "generate_text(model1_path, sequence1, max_len) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCxvbeKfRs35"
   },
   "source": [
    "The following was from an untrained model.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uSAOQPk8vOTE",
    "outputId": "69bedc13-2ac6-4ccc-c24a-dde11ef2015d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'What is the Privacy Act of 1974?\\n\\nPowers of the Privacy Act\\n\\nThe powers, powers, and procedures of the Privacy Act of 1974 may be broadly construed to cover any and all matters concerning:\\n\\npersonal information collected to fulfil the Privacy Act;\\n\\ninformation that is provided in any form, process, or form for the dissemination of certain data, or\\n\\nthe collection of personal information by a thirdâ€‘party; or\\n\\nthe collection of personal information through surveillance to ensure the integrity of the privacy of certain individuals.\\n\\nThis is based on the principle that access to personal information through surveillance warrants should also ensure confidentiality, confidentiality protected by law, and also should not be used for the collection of personal information.\\n\\nHow can I prevent collecting personal data by the Privacy Act?\\n\\nThe Privacy Act should enable people to do absolutely no harm. The Act does allow for the police to obtain information that could reveal information about your identity and that might be used for a criminal offence or for a criminal investigation. However, it could also allow the courts to use that information against you. To be sure you can be secure in your information and the privacy of all of your information, including the types of your information including, but not limited to:'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "generator(\"What is the Privacy Act of 1974?\", max_length=256, num_return_sequences=1)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNvBu4Jj2F8tAESALuZqmkV",
   "include_colab_link": true,
   "mount_file_id": "1WRB2uz0Mpfkw6AnDAxCOPwY_TT2tRizG",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
